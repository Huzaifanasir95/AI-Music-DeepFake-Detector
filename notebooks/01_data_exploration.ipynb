{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9f0de1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Configuration\n",
    "import yaml\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Librosa version: {librosa.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce055f",
   "metadata": {},
   "source": [
    "## 2. Set Up Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project paths\n",
    "PROJECT_ROOT = Path('..')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "CONFIG_DIR = PROJECT_ROOT / 'configs'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(RAW_DATA_DIR / 'real').mkdir(exist_ok=True)\n",
    "(RAW_DATA_DIR / 'synthetic').mkdir(exist_ok=True)\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Project Root: {PROJECT_ROOT.absolute()}\")\n",
    "print(f\"üìÅ Raw Data Directory: {RAW_DATA_DIR.absolute()}\")\n",
    "print(f\"üìÅ Processed Data Directory: {PROCESSED_DATA_DIR.absolute()}\")\n",
    "print(\"\\n‚úÖ Directory structure verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86339e",
   "metadata": {},
   "source": [
    "## 3. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29874fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "config_path = CONFIG_DIR / 'config.yaml'\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"‚úÖ Configuration loaded successfully!\\n\")\n",
    "    print(\"üìã Key Configuration Parameters:\")\n",
    "    print(f\"  - Sample Rate: {config['data']['sample_rate']} Hz\")\n",
    "    print(f\"  - Audio Duration: {config['data']['duration']} seconds\")\n",
    "    print(f\"  - N_FFT: {config['data']['n_fft']}\")\n",
    "    print(f\"  - N_Mels: {config['data']['n_mels']}\")\n",
    "    print(f\"  - N_MFCC: {config['data']['n_mfcc']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Configuration file not found. Using default values.\")\n",
    "    config = {\n",
    "        'data': {\n",
    "            'sample_rate': 22050,\n",
    "            'duration': 5,\n",
    "            'n_fft': 2048,\n",
    "            'n_mels': 128,\n",
    "            'n_mfcc': 13\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e55e4a",
   "metadata": {},
   "source": [
    "## 4. Check Dataset Availability\n",
    "\n",
    "Let's check if we have audio files in our data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d232433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported audio formats\n",
    "AUDIO_EXTENSIONS = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']\n",
    "\n",
    "def count_audio_files(directory):\n",
    "    \"\"\"Count audio files in a directory\"\"\"\n",
    "    if not directory.exists():\n",
    "        return 0\n",
    "    count = 0\n",
    "    for ext in AUDIO_EXTENSIONS:\n",
    "        count += len(list(directory.glob(f'*{ext}')))\n",
    "        count += len(list(directory.glob(f'**/*{ext}')))\n",
    "    return count\n",
    "\n",
    "# Count files\n",
    "real_audio_dir = RAW_DATA_DIR / 'real'\n",
    "synthetic_audio_dir = RAW_DATA_DIR / 'synthetic'\n",
    "\n",
    "num_real = count_audio_files(real_audio_dir)\n",
    "num_synthetic = count_audio_files(synthetic_audio_dir)\n",
    "\n",
    "print(\"üéµ Dataset Statistics:\")\n",
    "print(f\"  - Real Music Samples: {num_real}\")\n",
    "print(f\"  - Synthetic Music Samples: {num_synthetic}\")\n",
    "print(f\"  - Total Samples: {num_real + num_synthetic}\\n\")\n",
    "\n",
    "if num_real == 0 and num_synthetic == 0:\n",
    "    print(\"‚ö†Ô∏è  No audio files found!\")\n",
    "    print(\"\\nüìù Instructions to Add Data:\")\n",
    "    print(\"1. Place real music files in: data/raw/real/\")\n",
    "    print(\"2. Place synthetic music files in: data/raw/synthetic/\")\n",
    "    print(\"3. Supported formats: WAV, MP3, FLAC, OGG, M4A\")\n",
    "    print(\"\\nüí° For testing purposes, we'll generate sample data below.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset found! Ready for exploration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12c3c5",
   "metadata": {},
   "source": [
    "## 5. Generate Sample Data (For Testing)\n",
    "\n",
    "If you don't have real data yet, let's generate some synthetic audio samples for testing the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0784e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_audio(duration=5, sr=22050, frequency=440):\n",
    "    \"\"\"Generate a simple sine wave audio sample\"\"\"\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    # Add some harmonics for more realistic sound\n",
    "    audio = np.sin(2 * np.pi * frequency * t)\n",
    "    audio += 0.5 * np.sin(2 * np.pi * frequency * 2 * t)\n",
    "    audio += 0.3 * np.sin(2 * np.pi * frequency * 3 * t)\n",
    "    # Add noise\n",
    "    audio += 0.1 * np.random.randn(len(audio))\n",
    "    # Normalize\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "# Generate sample files if no data exists\n",
    "if num_real == 0 and num_synthetic == 0:\n",
    "    print(\"üéº Generating sample audio files for testing...\\n\")\n",
    "    \n",
    "    sr = config['data']['sample_rate']\n",
    "    duration = config['data']['duration']\n",
    "    \n",
    "    # Generate \"real\" samples (different frequencies)\n",
    "    for i, freq in enumerate([440, 523, 659, 784, 880], 1):\n",
    "        audio = generate_sample_audio(duration, sr, freq)\n",
    "        filepath = real_audio_dir / f'real_sample_{i}.wav'\n",
    "        sf.write(filepath, audio, sr)\n",
    "        print(f\"  ‚úì Created: {filepath.name}\")\n",
    "    \n",
    "    # Generate \"synthetic\" samples (slightly different characteristics)\n",
    "    for i, freq in enumerate([450, 533, 669, 794, 890], 1):\n",
    "        audio = generate_sample_audio(duration, sr, freq)\n",
    "        # Add more artificial characteristics\n",
    "        audio = audio * (1 + 0.1 * np.sin(2 * np.pi * 2 * np.arange(len(audio)) / sr))\n",
    "        filepath = synthetic_audio_dir / f'synthetic_sample_{i}.wav'\n",
    "        sf.write(filepath, audio, sr)\n",
    "        print(f\"  ‚úì Created: {filepath.name}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Sample data generated successfully!\")\n",
    "    print(\"   Note: These are simple test samples. Replace with real datasets for actual training.\")\n",
    "    \n",
    "    # Update counts\n",
    "    num_real = count_audio_files(real_audio_dir)\n",
    "    num_synthetic = count_audio_files(synthetic_audio_dir)\n",
    "else:\n",
    "    print(\"‚úÖ Using existing dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99911fbd",
   "metadata": {},
   "source": [
    "## 6. Load and Analyze Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b00280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(directory):\n",
    "    \"\"\"Get list of all audio files in directory\"\"\"\n",
    "    audio_files = []\n",
    "    for ext in AUDIO_EXTENSIONS:\n",
    "        audio_files.extend(list(directory.glob(f'*{ext}')))\n",
    "        audio_files.extend(list(directory.glob(f'**/*{ext}')))\n",
    "    return sorted(audio_files)\n",
    "\n",
    "# Get file lists\n",
    "real_files = get_audio_files(real_audio_dir)\n",
    "synthetic_files = get_audio_files(synthetic_audio_dir)\n",
    "\n",
    "print(f\"üìä Found {len(real_files)} real audio files\")\n",
    "print(f\"üìä Found {len(synthetic_files)} synthetic audio files\\n\")\n",
    "\n",
    "# Display first few files\n",
    "if real_files:\n",
    "    print(\"Real audio files (first 5):\")\n",
    "    for f in real_files[:5]:\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "if synthetic_files:\n",
    "    print(\"\\nSynthetic audio files (first 5):\")\n",
    "    for f in synthetic_files[:5]:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453bee1",
   "metadata": {},
   "source": [
    "## 7. Extract Audio Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_metadata(filepath):\n",
    "    \"\"\"Extract metadata from audio file\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(filepath, sr=None)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        \n",
    "        return {\n",
    "            'filename': filepath.name,\n",
    "            'duration': duration,\n",
    "            'sample_rate': sr,\n",
    "            'samples': len(y),\n",
    "            'channels': 1,  # librosa loads as mono by default\n",
    "            'label': 'real' if 'real' in str(filepath.parent) else 'synthetic'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Collect metadata for all files\n",
    "print(\"üìä Extracting metadata from audio files...\\n\")\n",
    "\n",
    "metadata_list = []\n",
    "for filepath in real_files + synthetic_files:\n",
    "    metadata = get_audio_metadata(filepath)\n",
    "    if metadata:\n",
    "        metadata_list.append(metadata)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(metadata_list)\n",
    "\n",
    "print(f\"‚úÖ Extracted metadata from {len(df)} audio files\\n\")\n",
    "print(\"First few entries:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83853eac",
   "metadata": {},
   "source": [
    "## 8. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Dataset Statistics:\\n\")\n",
    "print(df.groupby('label').agg({\n",
    "    'filename': 'count',\n",
    "    'duration': ['mean', 'min', 'max', 'std'],\n",
    "    'sample_rate': lambda x: x.mode()[0] if len(x) > 0 else None,\n",
    "    'samples': ['mean', 'min', 'max']\n",
    "}).round(2))\n",
    "\n",
    "print(\"\\nüìä Label Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da74f8d",
   "metadata": {},
   "source": [
    "## 9. Visualize Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3323cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Label distribution\n",
    "df['label'].value_counts().plot(kind='bar', ax=axes[0, 0], color=['#3498db', '#e74c3c'])\n",
    "axes[0, 0].set_title('Distribution of Real vs Synthetic Music', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Label')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Duration distribution\n",
    "df.boxplot(column='duration', by='label', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Audio Duration Distribution by Label', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Label')\n",
    "axes[0, 1].set_ylabel('Duration (seconds)')\n",
    "plt.sca(axes[0, 1])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 3. Sample rate distribution\n",
    "df.groupby('label')['sample_rate'].value_counts().unstack().plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Sample Rate Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Label')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].legend(title='Sample Rate (Hz)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 4. Duration histogram\n",
    "for label in df['label'].unique():\n",
    "    data = df[df['label'] == label]['duration']\n",
    "    axes[1, 1].hist(data, alpha=0.6, label=label, bins=15)\n",
    "axes[1, 1].set_title('Duration Distribution Histogram', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Duration (seconds)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dataset visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe07542",
   "metadata": {},
   "source": [
    "## 10. Load and Visualize Sample Audio\n",
    "\n",
    "Let's load a sample from each class and visualize their waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703421a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one sample from each class\n",
    "if real_files and synthetic_files:\n",
    "    sample_real = real_files[0]\n",
    "    sample_synthetic = synthetic_files[0]\n",
    "    \n",
    "    # Load audio\n",
    "    y_real, sr_real = librosa.load(sample_real, sr=config['data']['sample_rate'])\n",
    "    y_synthetic, sr_synthetic = librosa.load(sample_synthetic, sr=config['data']['sample_rate'])\n",
    "    \n",
    "    print(f\"üìª Loaded Samples:\")\n",
    "    print(f\"  Real: {sample_real.name} (Duration: {len(y_real)/sr_real:.2f}s)\")\n",
    "    print(f\"  Synthetic: {sample_synthetic.name} (Duration: {len(y_synthetic)/sr_synthetic:.2f}s)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No audio files available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c14e6",
   "metadata": {},
   "source": [
    "## 11. Waveform Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_files and synthetic_files:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    # Real audio waveform\n",
    "    librosa.display.waveshow(y_real, sr=sr_real, ax=axes[0], color='#3498db')\n",
    "    axes[0].set_title('Real Music - Waveform', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Time (s)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Synthetic audio waveform\n",
    "    librosa.display.waveshow(y_synthetic, sr=sr_synthetic, ax=axes[1], color='#e74c3c')\n",
    "    axes[1].set_title('Synthetic Music - Waveform', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time (s)')\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Waveform visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f1116f",
   "metadata": {},
   "source": [
    "## 12. Play Audio Samples\n",
    "\n",
    "Listen to the audio samples directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_files and synthetic_files:\n",
    "    print(\"üéµ Real Music Sample:\")\n",
    "    display(Audio(y_real, rate=sr_real))\n",
    "    \n",
    "    print(\"\\nüéµ Synthetic Music Sample:\")\n",
    "    display(Audio(y_synthetic, rate=sr_synthetic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb0685",
   "metadata": {},
   "source": [
    "## 13. Spectral Analysis\n",
    "\n",
    "Let's analyze the frequency content of the audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_files and synthetic_files:\n",
    "    # Compute spectrograms\n",
    "    D_real = librosa.amplitude_to_db(np.abs(librosa.stft(y_real)), ref=np.max)\n",
    "    D_synthetic = librosa.amplitude_to_db(np.abs(librosa.stft(y_synthetic)), ref=np.max)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Real audio spectrogram\n",
    "    img1 = librosa.display.specshow(D_real, sr=sr_real, x_axis='time', y_axis='hz', ax=axes[0], cmap='viridis')\n",
    "    axes[0].set_title('Real Music - Spectrogram', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Frequency (Hz)')\n",
    "    fig.colorbar(img1, ax=axes[0], format='%+2.0f dB')\n",
    "    \n",
    "    # Synthetic audio spectrogram\n",
    "    img2 = librosa.display.specshow(D_synthetic, sr=sr_synthetic, x_axis='time', y_axis='hz', ax=axes[1], cmap='viridis')\n",
    "    axes[1].set_title('Synthetic Music - Spectrogram', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time (s)')\n",
    "    axes[1].set_ylabel('Frequency (Hz)')\n",
    "    fig.colorbar(img2, ax=axes[1], format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Spectrogram visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd2f28a",
   "metadata": {},
   "source": [
    "## 14. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30addb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìã DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úÖ Total Audio Files: {len(df)}\")\n",
    "print(f\"   - Real Music: {len(df[df['label']=='real'])}\")\n",
    "print(f\"   - Synthetic Music: {len(df[df['label']=='synthetic'])}\")\n",
    "print(f\"\\nüìä Average Duration: {df['duration'].mean():.2f} seconds\")\n",
    "print(f\"üìä Sample Rate: {df['sample_rate'].mode()[0]} Hz\")\n",
    "print(f\"\\n‚úÖ Dataset is {'balanced' if abs(len(df[df['label']=='real']) - len(df[df['label']=='synthetic'])) < 5 else 'imbalanced'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù NEXT STEPS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1Ô∏è‚É£  Feature Extraction (Notebook 02):\")\n",
    "print(\"   - Extract mel-spectrograms\")\n",
    "print(\"   - Compute MFCCs\")\n",
    "print(\"   - Extract chroma features\")\n",
    "print(\"   - Save preprocessed features\")\n",
    "print(\"\\n2Ô∏è‚É£  Model Training (Notebook 03):\")\n",
    "print(\"   - Build Hybrid Transformer-Autoencoder model\")\n",
    "print(\"   - Train on preprocessed features\")\n",
    "print(\"   - Monitor training metrics\")\n",
    "print(\"\\n3Ô∏è‚É£  Model Evaluation (Notebook 04):\")\n",
    "print(\"   - Evaluate on test set\")\n",
    "print(\"   - Generate confusion matrix\")\n",
    "print(\"   - Analyze model performance\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüéâ Data Exploration Complete! Ready for feature extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf04fbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Key Takeaways\n",
    "\n",
    "1. **Dataset Structure**: We have successfully set up the data directory structure with separate folders for real and synthetic music.\n",
    "\n",
    "2. **Audio Characteristics**: We analyzed the duration, sample rate, and frequency content of our audio samples.\n",
    "\n",
    "3. **Visualization**: We created waveforms and spectrograms to understand the differences between real and synthetic music.\n",
    "\n",
    "4. **Next Steps**: We're ready to move to feature extraction in the next notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Tips for Real Data\n",
    "\n",
    "- **Real Music Sources**: Use royalty-free music from sources like Free Music Archive, YouTube Audio Library, or your own music collection\n",
    "- **Synthetic Music Sources**: Generate AI music using tools like MusicGen, Jukebox, MuseNet, or Stable Audio\n",
    "- **Data Diversity**: Include various genres, instruments, and styles for better model generalization\n",
    "- **Data Quality**: Ensure consistent audio quality and format across all samples\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
